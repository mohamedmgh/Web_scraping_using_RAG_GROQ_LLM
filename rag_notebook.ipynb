{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e80d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-groq langchain-community langchain-text-splitters sentence-transformers faiss-cpu pypdf python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04aeb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Desktop\\VS code File\\Rag_groq\\rag_croq_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import tempfile\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ec0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e1f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_18748\\3734642754.py:19: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader('C:/Users/PC/Desktop/VS code File/RAG_GROQ/RL exam 25-26.pdf')\n",
    "docs = loader.load()\n",
    "\n",
    "#if you want to use the web scrapping \n",
    "#loader = WebBaseLoader(website_url)\n",
    "#docs = loader.load()\n",
    "            \n",
    "            \n",
    "# Split text\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000, \n",
    "                chunk_overlap=200\n",
    "            )\n",
    "chunks = splitter.split_documents(docs)\n",
    "    \n",
    "            \n",
    "# Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5428553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the query, since we are going to use it multiple times.\n",
    "query = \"Give me the main comptetence of mohamed\"\n",
    "\n",
    "\n",
    "\n",
    "db = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3196a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = db.similarity_search(query, k=3)\n",
    "context = \"\\n\\n\".join([d.page_content for d in retrieved_docs])\n",
    "\n",
    " \n",
    "# initialize the retriever\n",
    "retriever = db.as_retriever(\n",
    "search_type=\"mmr\", #similarity\n",
    "search_kwargs={'k': 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c43fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "                        model=\"llama-3.3-70b-versatile\",  \n",
    "                        temperature=0.3,\n",
    "                        max_tokens=512\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909f8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=llm.invoke(\"resume this file in 2 ligne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf79781d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There is no file to resume. This conversation just started. If you provide a file or text, I can summarize it for you in 2 lines.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 42, 'total_tokens': 74, 'completion_time': 0.119644113, 'completion_tokens_details': None, 'prompt_time': 0.0019849, 'prompt_tokens_details': None, 'queue_time': 0.043722735, 'total_time': 0.121629013}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2741-82bf-72b0-bb32-d5bb83387870-0', usage_metadata={'input_tokens': 42, 'output_tokens': 32, 'total_tokens': 74})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd38d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Réponds à la question en te basant uniquement sur le contexte fourni.\n",
    "Si tu ne trouves pas la réponse dans le contexte, dis \"Je n'ai pas cette information dans le document.\"\n",
    "\n",
    "Contexte:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Réponse:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0586b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough              \n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "{\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| llm\n",
    "| output_parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b91f278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le document décrit un projet de création d'un modèle de langage léger (1-10 millions de paramètres) capable de réaliser des additions et des soustractions de petits entiers (jusqu'à 3-4 chiffres) à l'aide de l'apprentissage par renforcement. Le projet comporte plusieurs étapes :\\n\\n1. Création d'un jeu de données synthétiques d'expressions arithmétiques avec les résultats corrects.\\n2. Pré-entraînement du modèle sur un objectif de prédiction de token suivant.\\n3. Affinage du modèle à l'aide de l'apprentissage par renforcement pour améliorer la précision mathématique.\\n4. Évaluation du modèle à l'aide de métriques telles que la précision sur l'addition et la soustraction, la performance en fonction de la longueur des nombres, etc.\\n\\nLe document fournit également des détails sur l'architecture du modèle, les outils et les frameworks à utiliser, ainsi que des extensions optionnelles pour améliorer le projet. L'objectif final est de créer un modèle capable de raisonner à un niveau de chiffres et de réaliser des opérations arithmétiques avec précision.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\"donne moi le resume de ca\")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_croq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
